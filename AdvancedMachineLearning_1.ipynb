{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AML 1\n",
        "\n",
        "## Task 1"
      ],
      "metadata": {
        "id": "8CbBBa3I4-iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkzwe6JvslwJ",
        "outputId": "ca0e2217-5b93-48eb-f56c-b908c6fa7358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM6cJllX43wK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Dataset import as in Ptytorch docs\n",
        "ds_train = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor(),)\n",
        "ds_test = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor(),)\n",
        "\n",
        "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(ds_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "G-3Bo2dZ5b_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the labels from datasetg - taken from kaggle\n",
        "labels = {\n",
        "    0: 'T-shirt',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle Boot',\n",
        "}"
      ],
      "metadata": {
        "id": "f9kQYLuN5pla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the right device to perform the computations on\n",
        "device ='cuda' if torch.cuda.is_available else 'cpu'\n",
        "print(f'Using {device} device')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBvf_kPA5wKo",
        "outputId": "349291ed-1eea-4817-80fb-7bb3e7447bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of the model\n",
        "\n",
        "class FashionMnistClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FashionMnistClassifier, self).__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.drop1 = nn.Dropout2d(0.25)\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.drop2 = nn.Dropout2d(0.25)\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(7*7*64, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv_block_1(x)\n",
        "    out = self.drop1(out)\n",
        "    out = self.conv_block_2(out)\n",
        "    out = self.drop2(out)\n",
        "    out = self.linear_relu_stack(self.flatten(out))\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "-INniC6x6Go-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FashionMnistClassifier().to(device)\n",
        "print(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDW6qQt48SxN",
        "outputId": "113ee6c1-bd72-48ca-a896-dc01a2a3bd9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x7f2d868f0f90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings\n",
        "learning_rate = 1e-3\n",
        "epochs = 5\n",
        "\n",
        "loss = nn.CrossEntropyLoss()#nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "K3qISP-E8j5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch(dataloader, model, loss, opt):\n",
        "  model.train() # Setting model into train mode\n",
        "  samples = len(dataloader)*dataloader.batch_size\n",
        "  processed = 0\n",
        "  batch_num = 0\n",
        "\n",
        "  for data, label in dataloader:\n",
        "    data = data.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    predictions = model(data)\n",
        "    loss_result = loss(predictions, label)\n",
        "    loss_result.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    processed += len(data)\n",
        "    if batch_num % 100 == 0:\n",
        "      cur_loss = loss_result.item()\n",
        "      print(f'loss:{cur_loss:>7f} [{processed:>5d}/{samples:>5d}]')\n",
        "\n",
        "    batch_num += 1"
      ],
      "metadata": {
        "id": "PvncQ4Pn8jwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model, loss):\n",
        "  samples = len(dataloader.dataset)\n",
        "  n_batches = len(dataloader)\n",
        "  model.eval() # Disenables storing training data\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, label in dataloader:\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      predictions = model(data)\n",
        "\n",
        "      loss_val = loss(predictions, label).item()\n",
        "      correct += (predictions.argmax(1) == label).type(torch.float).sum().item()\n",
        "      test_loss += loss_val\n",
        "  test_loss /= n_batches\n",
        "  accuracy = correct/samples\n",
        "\n",
        "  return accuracy, test_loss, correct #, cm\n",
        "\n",
        "\n",
        "#     correct = 0\n",
        "#     with torch.no_grad():\n",
        "#         for data, label in dataloader:\n",
        "#             data, label = data.to(device), label.to(device)\n",
        "#             predictions = model(data)\n",
        "#             correct += (predictions.argmax(1) == label).type(torch.float).sum().item()\n",
        "#     accuracy = correct / len(dataloader.dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "LgZX39Ad_P2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(train, test, model, loss, opt, epochs):\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"# Epoch {e}\")\n",
        "    training_epoch(train, model, loss, opt)\n",
        "    train_accuracy, train_loss, train_correct = evaluate(train, model, loss)\n",
        "    test_accuracy, test_loss, test_correct = evaluate(test, model, loss)\n",
        "    print(f\"train_loss = {train_loss}, train_acc = {train_accuracy}, test_loss = {test_loss}, test_acc = {test_accuracy}\")\n"
      ],
      "metadata": {
        "id": "xjZk723A-t1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDdP1-MdsTUD",
        "outputId": "ef686e76-f489-47c2-b8cb-f0ef4066d5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
            "              ReLU-3           [-1, 32, 28, 28]               0\n",
            "         MaxPool2d-4           [-1, 32, 14, 14]               0\n",
            "         Dropout2d-5           [-1, 32, 14, 14]               0\n",
            "            Conv2d-6           [-1, 64, 14, 14]          18,496\n",
            "       BatchNorm2d-7           [-1, 64, 14, 14]             128\n",
            "              ReLU-8           [-1, 64, 14, 14]               0\n",
            "         MaxPool2d-9             [-1, 64, 7, 7]               0\n",
            "        Dropout2d-10             [-1, 64, 7, 7]               0\n",
            "          Flatten-11                 [-1, 3136]               0\n",
            "           Linear-12                  [-1, 512]       1,606,144\n",
            "             ReLU-13                  [-1, 512]               0\n",
            "           Linear-14                  [-1, 512]         262,656\n",
            "             ReLU-15                  [-1, 512]               0\n",
            "           Linear-16                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 1,892,938\n",
            "Trainable params: 1,892,938\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.04\n",
            "Params size (MB): 7.22\n",
            "Estimated Total Size (MB): 8.27\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(train_loader, test_loader, model, loss, optimizer, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EExLE-6BEVme",
        "outputId": "1c3ed073-ee4e-46a5-cff8-090820a6910f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Epoch 0\n",
            "loss:2.327907 [   32/60000]\n",
            "loss:2.262675 [ 3232/60000]\n",
            "loss:2.177407 [ 6432/60000]\n",
            "loss:2.074695 [ 9632/60000]\n",
            "loss:1.940964 [12832/60000]\n",
            "loss:1.825862 [16032/60000]\n",
            "loss:1.653764 [19232/60000]\n",
            "loss:1.525925 [22432/60000]\n",
            "loss:1.270920 [25632/60000]\n",
            "loss:1.102172 [28832/60000]\n",
            "loss:1.189249 [32032/60000]\n",
            "loss:1.206663 [35232/60000]\n",
            "loss:1.094579 [38432/60000]\n",
            "loss:0.931631 [41632/60000]\n",
            "loss:0.952184 [44832/60000]\n",
            "loss:0.775432 [48032/60000]\n",
            "loss:0.980141 [51232/60000]\n",
            "loss:0.950272 [54432/60000]\n",
            "loss:0.508294 [57632/60000]\n",
            "train_loss = 0.7308023591518402, train_acc = 0.7579, test_loss = 0.7367126640801231, test_acc = 0.7553\n",
            "# Epoch 1\n",
            "loss:1.026207 [   32/60000]\n",
            "loss:0.640689 [ 3232/60000]\n",
            "loss:0.980416 [ 6432/60000]\n",
            "loss:0.625771 [ 9632/60000]\n",
            "loss:0.909272 [12832/60000]\n",
            "loss:0.789165 [16032/60000]\n",
            "loss:0.731916 [19232/60000]\n",
            "loss:0.656753 [22432/60000]\n",
            "loss:0.519451 [25632/60000]\n",
            "loss:0.768047 [28832/60000]\n",
            "loss:0.474810 [32032/60000]\n",
            "loss:0.643805 [35232/60000]\n",
            "loss:0.566201 [38432/60000]\n",
            "loss:0.443385 [41632/60000]\n",
            "loss:0.709944 [44832/60000]\n",
            "loss:0.531897 [48032/60000]\n",
            "loss:0.460812 [51232/60000]\n",
            "loss:0.651925 [54432/60000]\n",
            "loss:0.508028 [57632/60000]\n",
            "train_loss = 0.547760191655159, train_acc = 0.79865, test_loss = 0.5606239327607444, test_acc = 0.7904\n",
            "# Epoch 2\n",
            "loss:0.373456 [   32/60000]\n",
            "loss:0.508704 [ 3232/60000]\n",
            "loss:0.626505 [ 6432/60000]\n",
            "loss:0.516579 [ 9632/60000]\n",
            "loss:0.478411 [12832/60000]\n",
            "loss:0.579266 [16032/60000]\n",
            "loss:0.438224 [19232/60000]\n",
            "loss:0.600709 [22432/60000]\n",
            "loss:0.728805 [25632/60000]\n",
            "loss:0.506071 [28832/60000]\n",
            "loss:0.731366 [32032/60000]\n",
            "loss:0.443318 [35232/60000]\n",
            "loss:0.506640 [38432/60000]\n",
            "loss:0.567645 [41632/60000]\n",
            "loss:0.368850 [44832/60000]\n",
            "loss:0.586386 [48032/60000]\n",
            "loss:0.742214 [51232/60000]\n",
            "loss:0.533818 [54432/60000]\n",
            "loss:0.356944 [57632/60000]\n",
            "train_loss = 0.47442568293412524, train_acc = 0.8312666666666667, test_loss = 0.4914831033529946, test_acc = 0.8225\n",
            "# Epoch 3\n",
            "loss:0.499151 [   32/60000]\n",
            "loss:0.532048 [ 3232/60000]\n",
            "loss:0.269735 [ 6432/60000]\n",
            "loss:0.550949 [ 9632/60000]\n",
            "loss:0.706145 [12832/60000]\n",
            "loss:0.521731 [16032/60000]\n",
            "loss:0.494041 [19232/60000]\n",
            "loss:0.297425 [22432/60000]\n",
            "loss:0.426116 [25632/60000]\n",
            "loss:0.728854 [28832/60000]\n",
            "loss:0.559225 [32032/60000]\n",
            "loss:0.354450 [35232/60000]\n",
            "loss:0.332345 [38432/60000]\n",
            "loss:0.325537 [41632/60000]\n",
            "loss:0.461938 [44832/60000]\n",
            "loss:0.377632 [48032/60000]\n",
            "loss:0.514083 [51232/60000]\n",
            "loss:0.545412 [54432/60000]\n",
            "loss:0.504097 [57632/60000]\n",
            "train_loss = 0.43119427864551546, train_acc = 0.8471333333333333, test_loss = 0.45085986658407096, test_acc = 0.8397\n",
            "# Epoch 4\n",
            "loss:0.210942 [   32/60000]\n",
            "loss:0.453416 [ 3232/60000]\n",
            "loss:0.545074 [ 6432/60000]\n",
            "loss:0.799550 [ 9632/60000]\n",
            "loss:0.308046 [12832/60000]\n",
            "loss:0.322664 [16032/60000]\n",
            "loss:0.272779 [19232/60000]\n",
            "loss:0.519632 [22432/60000]\n",
            "loss:0.449007 [25632/60000]\n",
            "loss:0.481312 [28832/60000]\n",
            "loss:0.304200 [32032/60000]\n",
            "loss:0.560224 [35232/60000]\n",
            "loss:0.655422 [38432/60000]\n",
            "loss:0.569451 [41632/60000]\n",
            "loss:0.357227 [44832/60000]\n",
            "loss:0.405532 [48032/60000]\n",
            "loss:0.361336 [51232/60000]\n",
            "loss:0.339268 [54432/60000]\n",
            "loss:0.400873 [57632/60000]\n",
            "train_loss = 0.40612333482503893, train_acc = 0.8559166666666667, test_loss = 0.427337247675981, test_acc = 0.8466\n",
            "# Epoch 5\n",
            "loss:0.376901 [   32/60000]\n",
            "loss:0.290589 [ 3232/60000]\n",
            "loss:0.770815 [ 6432/60000]\n",
            "loss:0.360953 [ 9632/60000]\n",
            "loss:0.256536 [12832/60000]\n",
            "loss:0.307459 [16032/60000]\n",
            "loss:0.307413 [19232/60000]\n",
            "loss:0.331144 [22432/60000]\n",
            "loss:0.379892 [25632/60000]\n",
            "loss:0.254878 [28832/60000]\n",
            "loss:0.372435 [32032/60000]\n",
            "loss:0.373527 [35232/60000]\n",
            "loss:0.685388 [38432/60000]\n",
            "loss:0.416630 [41632/60000]\n",
            "loss:0.454774 [44832/60000]\n",
            "loss:0.307673 [48032/60000]\n",
            "loss:0.295798 [51232/60000]\n",
            "loss:0.328506 [54432/60000]\n",
            "loss:0.437492 [57632/60000]\n",
            "train_loss = 0.3786610119978587, train_acc = 0.8662166666666666, test_loss = 0.4019385380581164, test_acc = 0.8591\n",
            "# Epoch 6\n",
            "loss:0.371601 [   32/60000]\n",
            "loss:0.257332 [ 3232/60000]\n",
            "loss:0.188858 [ 6432/60000]\n",
            "loss:0.632270 [ 9632/60000]\n",
            "loss:0.382597 [12832/60000]\n",
            "loss:0.510536 [16032/60000]\n",
            "loss:0.398043 [19232/60000]\n",
            "loss:0.351574 [22432/60000]\n",
            "loss:0.358938 [25632/60000]\n",
            "loss:0.275732 [28832/60000]\n",
            "loss:0.437306 [32032/60000]\n",
            "loss:0.319138 [35232/60000]\n",
            "loss:0.475739 [38432/60000]\n",
            "loss:0.441918 [41632/60000]\n",
            "loss:0.336003 [44832/60000]\n",
            "loss:0.298694 [48032/60000]\n",
            "loss:0.134619 [51232/60000]\n",
            "loss:0.349970 [54432/60000]\n",
            "loss:0.311325 [57632/60000]\n",
            "train_loss = 0.3604854104200999, train_acc = 0.8736833333333334, test_loss = 0.38445596168406854, test_acc = 0.8638\n",
            "# Epoch 7\n",
            "loss:0.378073 [   32/60000]\n",
            "loss:0.403351 [ 3232/60000]\n",
            "loss:0.429577 [ 6432/60000]\n",
            "loss:0.390355 [ 9632/60000]\n",
            "loss:0.393618 [12832/60000]\n",
            "loss:0.277753 [16032/60000]\n",
            "loss:0.550279 [19232/60000]\n",
            "loss:0.322357 [22432/60000]\n",
            "loss:0.396000 [25632/60000]\n",
            "loss:0.430367 [28832/60000]\n",
            "loss:0.331214 [32032/60000]\n",
            "loss:0.587013 [35232/60000]\n",
            "loss:0.279820 [38432/60000]\n",
            "loss:0.408836 [41632/60000]\n",
            "loss:0.311922 [44832/60000]\n",
            "loss:0.307563 [48032/60000]\n",
            "loss:0.678823 [51232/60000]\n",
            "loss:0.337953 [54432/60000]\n",
            "loss:0.334653 [57632/60000]\n",
            "train_loss = 0.3490473731517792, train_acc = 0.8766333333333334, test_loss = 0.37497671572164226, test_acc = 0.8683\n",
            "# Epoch 8\n",
            "loss:0.525697 [   32/60000]\n",
            "loss:0.722846 [ 3232/60000]\n",
            "loss:0.296114 [ 6432/60000]\n",
            "loss:0.265349 [ 9632/60000]\n",
            "loss:0.488242 [12832/60000]\n",
            "loss:0.592607 [16032/60000]\n",
            "loss:0.251601 [19232/60000]\n",
            "loss:0.350988 [22432/60000]\n",
            "loss:0.386076 [25632/60000]\n",
            "loss:0.663156 [28832/60000]\n",
            "loss:0.247588 [32032/60000]\n",
            "loss:0.165246 [35232/60000]\n",
            "loss:0.325705 [38432/60000]\n",
            "loss:0.324946 [41632/60000]\n",
            "loss:0.481670 [44832/60000]\n",
            "loss:0.417053 [48032/60000]\n",
            "loss:0.324663 [51232/60000]\n",
            "loss:0.388860 [54432/60000]\n",
            "loss:0.209558 [57632/60000]\n",
            "train_loss = 0.3343891260604064, train_acc = 0.88365, test_loss = 0.36216376712337467, test_acc = 0.8706\n",
            "# Epoch 9\n",
            "loss:0.264082 [   32/60000]\n",
            "loss:0.262886 [ 3232/60000]\n",
            "loss:0.333635 [ 6432/60000]\n",
            "loss:0.265194 [ 9632/60000]\n",
            "loss:0.280277 [12832/60000]\n",
            "loss:0.263386 [16032/60000]\n",
            "loss:0.328875 [19232/60000]\n",
            "loss:0.271627 [22432/60000]\n",
            "loss:0.534017 [25632/60000]\n",
            "loss:0.242048 [28832/60000]\n",
            "loss:0.092128 [32032/60000]\n",
            "loss:0.463465 [35232/60000]\n",
            "loss:0.585713 [38432/60000]\n",
            "loss:0.261100 [41632/60000]\n",
            "loss:0.448412 [44832/60000]\n",
            "loss:0.605158 [48032/60000]\n",
            "loss:0.324006 [51232/60000]\n",
            "loss:0.560168 [54432/60000]\n",
            "loss:0.378931 [57632/60000]\n",
            "train_loss = 0.3204442815899849, train_acc = 0.8871333333333333, test_loss = 0.3486699561912793, test_acc = 0.8757\n",
            "# Epoch 10\n",
            "loss:0.468813 [   32/60000]\n",
            "loss:0.459697 [ 3232/60000]\n",
            "loss:0.520787 [ 6432/60000]\n",
            "loss:0.618760 [ 9632/60000]\n",
            "loss:0.263235 [12832/60000]\n",
            "loss:0.294153 [16032/60000]\n",
            "loss:0.277682 [19232/60000]\n",
            "loss:0.250002 [22432/60000]\n",
            "loss:0.341792 [25632/60000]\n",
            "loss:0.348415 [28832/60000]\n",
            "loss:0.377211 [32032/60000]\n",
            "loss:0.461518 [35232/60000]\n",
            "loss:0.261490 [38432/60000]\n",
            "loss:0.541418 [41632/60000]\n",
            "loss:0.307925 [44832/60000]\n",
            "loss:0.222953 [48032/60000]\n",
            "loss:0.288262 [51232/60000]\n",
            "loss:0.522544 [54432/60000]\n",
            "loss:0.323867 [57632/60000]\n",
            "train_loss = 0.31019812322854995, train_acc = 0.89125, test_loss = 0.3398719681813694, test_acc = 0.8808\n",
            "# Epoch 11\n",
            "loss:0.364826 [   32/60000]\n",
            "loss:0.344276 [ 3232/60000]\n",
            "loss:0.243082 [ 6432/60000]\n",
            "loss:0.259631 [ 9632/60000]\n",
            "loss:0.145862 [12832/60000]\n",
            "loss:0.515803 [16032/60000]\n",
            "loss:0.380307 [19232/60000]\n",
            "loss:0.474858 [22432/60000]\n",
            "loss:0.217749 [25632/60000]\n",
            "loss:0.285812 [28832/60000]\n",
            "loss:0.328133 [32032/60000]\n",
            "loss:0.245447 [35232/60000]\n",
            "loss:0.531865 [38432/60000]\n",
            "loss:0.271840 [41632/60000]\n",
            "loss:0.351343 [44832/60000]\n",
            "loss:0.406151 [48032/60000]\n",
            "loss:0.340509 [51232/60000]\n",
            "loss:0.443159 [54432/60000]\n",
            "loss:0.650494 [57632/60000]\n",
            "train_loss = 0.3057401789923509, train_acc = 0.8923333333333333, test_loss = 0.3375338911772155, test_acc = 0.8779\n",
            "# Epoch 12\n",
            "loss:0.160892 [   32/60000]\n",
            "loss:0.161349 [ 3232/60000]\n",
            "loss:0.185906 [ 6432/60000]\n",
            "loss:0.370390 [ 9632/60000]\n",
            "loss:0.215164 [12832/60000]\n",
            "loss:0.390840 [16032/60000]\n",
            "loss:0.268987 [19232/60000]\n",
            "loss:0.151344 [22432/60000]\n",
            "loss:0.292146 [25632/60000]\n",
            "loss:0.202374 [28832/60000]\n",
            "loss:0.490693 [32032/60000]\n",
            "loss:0.224161 [35232/60000]\n",
            "loss:0.365004 [38432/60000]\n",
            "loss:0.312676 [41632/60000]\n",
            "loss:0.347806 [44832/60000]\n",
            "loss:0.248832 [48032/60000]\n",
            "loss:0.263483 [51232/60000]\n",
            "loss:0.392295 [54432/60000]\n",
            "loss:0.230568 [57632/60000]\n",
            "train_loss = 0.2980000337501367, train_acc = 0.8941833333333333, test_loss = 0.3305143001980294, test_acc = 0.8809\n",
            "# Epoch 13\n",
            "loss:0.389171 [   32/60000]\n",
            "loss:0.275106 [ 3232/60000]\n",
            "loss:0.142889 [ 6432/60000]\n",
            "loss:0.316247 [ 9632/60000]\n",
            "loss:0.208296 [12832/60000]\n",
            "loss:0.169956 [16032/60000]\n",
            "loss:0.326579 [19232/60000]\n",
            "loss:0.176426 [22432/60000]\n",
            "loss:0.218188 [25632/60000]\n",
            "loss:0.258241 [28832/60000]\n",
            "loss:0.339554 [32032/60000]\n",
            "loss:0.333761 [35232/60000]\n",
            "loss:0.389172 [38432/60000]\n",
            "loss:0.627741 [41632/60000]\n",
            "loss:0.510102 [44832/60000]\n",
            "loss:0.217936 [48032/60000]\n",
            "loss:0.358107 [51232/60000]\n",
            "loss:0.115795 [54432/60000]\n",
            "loss:0.377790 [57632/60000]\n",
            "train_loss = 0.2936194680353006, train_acc = 0.8958, test_loss = 0.3267947925974767, test_acc = 0.8834\n",
            "# Epoch 14\n",
            "loss:0.225181 [   32/60000]\n",
            "loss:0.315211 [ 3232/60000]\n",
            "loss:0.243699 [ 6432/60000]\n",
            "loss:0.543843 [ 9632/60000]\n",
            "loss:0.447534 [12832/60000]\n",
            "loss:0.302705 [16032/60000]\n",
            "loss:0.273200 [19232/60000]\n",
            "loss:0.297311 [22432/60000]\n",
            "loss:0.279674 [25632/60000]\n",
            "loss:0.517319 [28832/60000]\n",
            "loss:0.263847 [32032/60000]\n",
            "loss:0.176602 [35232/60000]\n",
            "loss:0.479583 [38432/60000]\n",
            "loss:0.138921 [41632/60000]\n",
            "loss:0.203828 [44832/60000]\n",
            "loss:0.230225 [48032/60000]\n",
            "loss:0.583720 [51232/60000]\n",
            "loss:0.292211 [54432/60000]\n",
            "loss:0.541027 [57632/60000]\n",
            "train_loss = 0.28254036642313, train_acc = 0.90065, test_loss = 0.31748436191401924, test_acc = 0.8871\n",
            "# Epoch 15\n",
            "loss:0.357769 [   32/60000]\n",
            "loss:0.254170 [ 3232/60000]\n",
            "loss:0.284637 [ 6432/60000]\n",
            "loss:0.390435 [ 9632/60000]\n",
            "loss:0.325005 [12832/60000]\n",
            "loss:0.159059 [16032/60000]\n",
            "loss:0.373876 [19232/60000]\n",
            "loss:0.126930 [22432/60000]\n",
            "loss:0.480913 [25632/60000]\n",
            "loss:0.325627 [28832/60000]\n",
            "loss:0.222557 [32032/60000]\n",
            "loss:0.337483 [35232/60000]\n",
            "loss:0.404357 [38432/60000]\n",
            "loss:0.412967 [41632/60000]\n",
            "loss:0.360981 [44832/60000]\n",
            "loss:0.151669 [48032/60000]\n",
            "loss:0.265839 [51232/60000]\n",
            "loss:0.263514 [54432/60000]\n",
            "loss:0.378977 [57632/60000]\n",
            "train_loss = 0.2947318808734417, train_acc = 0.8946666666666667, test_loss = 0.33123338839021355, test_acc = 0.8809\n",
            "# Epoch 16\n",
            "loss:0.361440 [   32/60000]\n",
            "loss:0.384307 [ 3232/60000]\n",
            "loss:0.364439 [ 6432/60000]\n",
            "loss:0.174661 [ 9632/60000]\n",
            "loss:0.347376 [12832/60000]\n",
            "loss:0.224931 [16032/60000]\n",
            "loss:0.393685 [19232/60000]\n",
            "loss:0.261961 [22432/60000]\n",
            "loss:0.228955 [25632/60000]\n",
            "loss:0.600602 [28832/60000]\n",
            "loss:0.213227 [32032/60000]\n",
            "loss:0.140991 [35232/60000]\n",
            "loss:0.390574 [38432/60000]\n",
            "loss:0.516903 [41632/60000]\n",
            "loss:0.349526 [44832/60000]\n",
            "loss:0.305137 [48032/60000]\n",
            "loss:0.315578 [51232/60000]\n",
            "loss:0.315861 [54432/60000]\n",
            "loss:0.244522 [57632/60000]\n",
            "train_loss = 0.2704797589759032, train_acc = 0.9048166666666667, test_loss = 0.30635123423779737, test_acc = 0.8917\n",
            "# Epoch 17\n",
            "loss:0.298220 [   32/60000]\n",
            "loss:0.142161 [ 3232/60000]\n",
            "loss:0.203202 [ 6432/60000]\n",
            "loss:0.143664 [ 9632/60000]\n",
            "loss:0.297907 [12832/60000]\n",
            "loss:0.235901 [16032/60000]\n",
            "loss:0.137181 [19232/60000]\n",
            "loss:0.202641 [22432/60000]\n",
            "loss:0.159151 [25632/60000]\n",
            "loss:0.226537 [28832/60000]\n",
            "loss:0.287039 [32032/60000]\n",
            "loss:0.290247 [35232/60000]\n",
            "loss:0.372567 [38432/60000]\n",
            "loss:0.300908 [41632/60000]\n",
            "loss:0.374019 [44832/60000]\n",
            "loss:0.419528 [48032/60000]\n",
            "loss:0.165266 [51232/60000]\n",
            "loss:0.297669 [54432/60000]\n",
            "loss:0.508925 [57632/60000]\n",
            "train_loss = 0.27067020001212755, train_acc = 0.9028, test_loss = 0.30683952775864176, test_acc = 0.8886\n",
            "# Epoch 18\n",
            "loss:0.225230 [   32/60000]\n",
            "loss:0.860517 [ 3232/60000]\n",
            "loss:0.209974 [ 6432/60000]\n",
            "loss:0.250576 [ 9632/60000]\n",
            "loss:0.473937 [12832/60000]\n",
            "loss:0.346855 [16032/60000]\n",
            "loss:0.311011 [19232/60000]\n",
            "loss:0.249698 [22432/60000]\n",
            "loss:0.128727 [25632/60000]\n",
            "loss:0.314391 [28832/60000]\n",
            "loss:0.521389 [32032/60000]\n",
            "loss:0.641884 [35232/60000]\n",
            "loss:0.388196 [38432/60000]\n",
            "loss:0.113338 [41632/60000]\n",
            "loss:0.153704 [44832/60000]\n",
            "loss:0.378877 [48032/60000]\n",
            "loss:0.317764 [51232/60000]\n",
            "loss:0.441249 [54432/60000]\n",
            "loss:0.338458 [57632/60000]\n",
            "train_loss = 0.26070367748538653, train_acc = 0.90795, test_loss = 0.2976768780916263, test_acc = 0.8943\n",
            "# Epoch 19\n",
            "loss:0.172541 [   32/60000]\n",
            "loss:0.483109 [ 3232/60000]\n",
            "loss:0.328482 [ 6432/60000]\n",
            "loss:0.128392 [ 9632/60000]\n",
            "loss:0.289579 [12832/60000]\n",
            "loss:0.165026 [16032/60000]\n",
            "loss:0.270763 [19232/60000]\n",
            "loss:0.152859 [22432/60000]\n",
            "loss:0.145497 [25632/60000]\n",
            "loss:0.372329 [28832/60000]\n",
            "loss:0.365904 [32032/60000]\n",
            "loss:0.090162 [35232/60000]\n",
            "loss:0.359834 [38432/60000]\n",
            "loss:0.308002 [41632/60000]\n",
            "loss:0.172475 [44832/60000]\n",
            "loss:0.304413 [48032/60000]\n",
            "loss:0.336938 [51232/60000]\n",
            "loss:0.233071 [54432/60000]\n",
            "loss:0.326713 [57632/60000]\n",
            "train_loss = 0.27235795814991, train_acc = 0.9012, test_loss = 0.3098005715507669, test_acc = 0.888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2"
      ],
      "metadata": {
        "id": "M27sfUwm-yMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(torch.nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.encoder = torch.nn.Sequential(\n",
        "        torch.nn.Linear(input_size, 128),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(128, 64),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(64,32),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(32,16)\n",
        "    )\n",
        "\n",
        "    self.decoder = torch.nn.Sequential(\n",
        "        torch.nn.Linear(16,32),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(32,64),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(64,128),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(128,input_size),\n",
        "        torch.nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.encoder(x)\n",
        "    out = self.decoder(out)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "5l8_ucTTCR_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor())\n",
        "ds_test = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor())\n",
        "batch_size=32\n",
        "train_dataloader = DataLoader(ds_train,batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(ds_test,batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = AutoEncoder(28*28)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr = 1e-1,\n",
        "                             weight_decay = 1e-8)\n",
        "\n",
        "loss_f = torch.nn.MSELoss()\n",
        "\n",
        "# Selecting the right device to perform the computations on\n",
        "device ='cuda' if torch.cuda.is_available else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-5phlXRLue4",
        "outputId": "8f5dde7f-d1cd-4660-da51-db537960fbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_epoch_train(model, optimizer, loss, train_dataloader, device):\n",
        "  model.train()\n",
        "  processed_images = 0\n",
        "  current_batch_index = 0\n",
        "  samples = len(train_dataloader.dataset)\n",
        "  for image, _ in train_dataloader:\n",
        "    image = image.to(device)\n",
        "    image = image.reshape(-1,28*28)\n",
        "\n",
        "    reconstructed_image = model(image)\n",
        "    computed_loss = loss(reconstructed_image, image)\n",
        "    computed_loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    processed_images += len(image)\n",
        "    if current_batch_index % 100 == 0:\n",
        "      current_loss_value = computed_loss.item()\n",
        "      print(f'loss:{current_loss_value:>7f} [{processed_images:>5d}/{samples:>5d}]')\n",
        "    current_batch_index +=1\n"
      ],
      "metadata": {
        "id": "YWnKX8drL8uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loss, dataloader, device):\n",
        "  model.eval()\n",
        "  samples = len(dataloader.dataset)\n",
        "  n_batches = len(dataloader)\n",
        "  total_loss = 0\n",
        "  samples = len(dataloader.dataset)\n",
        "  for image, _ in dataloader:\n",
        "    image = image.to(device)\n",
        "    image = image.reshape(-1, 28*28)\n",
        "\n",
        "    reconstructed_image = model(image)\n",
        "    computed_loss = loss(reconstructed_image, image)\n",
        "    total_loss+=computed_loss.item()\n",
        "  return total_loss/n_batches"
      ],
      "metadata": {
        "id": "VqXrXKP4FYvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(train, test, model, loss, opt, epochs):\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"# Epoch {e}\")\n",
        "    one_epoch_train(model,opt, loss, train, device)\n",
        "    train_loss = evaluate(model, loss, train,device)\n",
        "    test_loss = evaluate(model, loss, test,device)\n",
        "    print(f\"train_loss = {train_loss}, test_loss = {test_loss}\")\n",
        "run_training(train_dataloader, test_dataloader, model, loss_f, optimizer, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB_Fyu8XOy4u",
        "outputId": "73b113f9-aca1-4085-ac5b-5ebb82771429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Epoch 0\n",
            "loss:0.230689 [   32/60000]\n",
            "loss:0.221271 [ 3232/60000]\n",
            "loss:0.209455 [ 6432/60000]\n",
            "loss:0.208472 [ 9632/60000]\n",
            "loss:0.204828 [12832/60000]\n",
            "loss:0.232972 [16032/60000]\n",
            "loss:0.181306 [19232/60000]\n",
            "loss:0.238475 [22432/60000]\n",
            "loss:0.192490 [25632/60000]\n",
            "loss:0.245523 [28832/60000]\n",
            "loss:0.242361 [32032/60000]\n",
            "loss:0.213575 [35232/60000]\n",
            "loss:0.191897 [38432/60000]\n",
            "loss:0.214855 [41632/60000]\n",
            "loss:0.205197 [44832/60000]\n",
            "loss:0.222642 [48032/60000]\n",
            "loss:0.158204 [51232/60000]\n",
            "loss:0.176766 [54432/60000]\n",
            "loss:0.211015 [57632/60000]\n",
            "train_loss = 0.20644534345467885, test_loss = 0.20652934332815603\n",
            "# Epoch 1\n",
            "loss:0.228290 [   32/60000]\n",
            "loss:0.225174 [ 3232/60000]\n",
            "loss:0.199176 [ 6432/60000]\n",
            "loss:0.209543 [ 9632/60000]\n",
            "loss:0.244000 [12832/60000]\n",
            "loss:0.212643 [16032/60000]\n",
            "loss:0.217909 [19232/60000]\n",
            "loss:0.178870 [22432/60000]\n",
            "loss:0.179798 [25632/60000]\n",
            "loss:0.197164 [28832/60000]\n",
            "loss:0.220349 [32032/60000]\n",
            "loss:0.237585 [35232/60000]\n",
            "loss:0.243746 [38432/60000]\n",
            "loss:0.230232 [41632/60000]\n",
            "loss:0.135702 [44832/60000]\n",
            "loss:0.185241 [48032/60000]\n",
            "loss:0.224726 [51232/60000]\n",
            "loss:0.202354 [54432/60000]\n",
            "loss:0.175677 [57632/60000]\n",
            "train_loss = 0.20644534358978273, test_loss = 0.20657736620011802\n",
            "# Epoch 2\n",
            "loss:0.229131 [   32/60000]\n",
            "loss:0.192752 [ 3232/60000]\n",
            "loss:0.197335 [ 6432/60000]\n",
            "loss:0.241428 [ 9632/60000]\n",
            "loss:0.188715 [12832/60000]\n",
            "loss:0.211813 [16032/60000]\n",
            "loss:0.188018 [19232/60000]\n",
            "loss:0.208768 [22432/60000]\n",
            "loss:0.207132 [25632/60000]\n",
            "loss:0.211389 [28832/60000]\n",
            "loss:0.204826 [32032/60000]\n",
            "loss:0.205746 [35232/60000]\n",
            "loss:0.166350 [38432/60000]\n",
            "loss:0.195273 [41632/60000]\n",
            "loss:0.236284 [44832/60000]\n",
            "loss:0.205235 [48032/60000]\n",
            "loss:0.197922 [51232/60000]\n",
            "loss:0.214469 [54432/60000]\n",
            "loss:0.212231 [57632/60000]\n",
            "train_loss = 0.2064453433831533, test_loss = 0.20643308515937184\n",
            "# Epoch 3\n",
            "loss:0.147837 [   32/60000]\n",
            "loss:0.195808 [ 3232/60000]\n",
            "loss:0.215545 [ 6432/60000]\n",
            "loss:0.221386 [ 9632/60000]\n",
            "loss:0.197508 [12832/60000]\n",
            "loss:0.196028 [16032/60000]\n",
            "loss:0.235780 [19232/60000]\n",
            "loss:0.216684 [22432/60000]\n",
            "loss:0.162506 [25632/60000]\n",
            "loss:0.223799 [28832/60000]\n",
            "loss:0.214167 [32032/60000]\n",
            "loss:0.201012 [35232/60000]\n",
            "loss:0.245807 [38432/60000]\n",
            "loss:0.208143 [41632/60000]\n",
            "loss:0.195477 [44832/60000]\n",
            "loss:0.170705 [48032/60000]\n",
            "loss:0.203823 [51232/60000]\n",
            "loss:0.200408 [54432/60000]\n",
            "loss:0.204769 [57632/60000]\n",
            "train_loss = 0.20644534367720285, test_loss = 0.2064682310000776\n",
            "# Epoch 4\n",
            "loss:0.205376 [   32/60000]\n",
            "loss:0.200734 [ 3232/60000]\n",
            "loss:0.189479 [ 6432/60000]\n",
            "loss:0.177521 [ 9632/60000]\n",
            "loss:0.201696 [12832/60000]\n",
            "loss:0.154825 [16032/60000]\n",
            "loss:0.208496 [19232/60000]\n",
            "loss:0.187056 [22432/60000]\n",
            "loss:0.203473 [25632/60000]\n",
            "loss:0.207487 [28832/60000]\n",
            "loss:0.194034 [32032/60000]\n",
            "loss:0.203788 [35232/60000]\n",
            "loss:0.193598 [38432/60000]\n",
            "loss:0.181290 [41632/60000]\n",
            "loss:0.211971 [44832/60000]\n",
            "loss:0.195943 [48032/60000]\n",
            "loss:0.218910 [51232/60000]\n",
            "loss:0.201423 [54432/60000]\n",
            "loss:0.209378 [57632/60000]\n",
            "train_loss = 0.20644534401098888, test_loss = 0.20652541694359278\n",
            "# Epoch 5\n",
            "loss:0.201297 [   32/60000]\n",
            "loss:0.162931 [ 3232/60000]\n",
            "loss:0.204564 [ 6432/60000]\n",
            "loss:0.219700 [ 9632/60000]\n",
            "loss:0.224609 [12832/60000]\n",
            "loss:0.218469 [16032/60000]\n",
            "loss:0.191551 [19232/60000]\n",
            "loss:0.249763 [22432/60000]\n",
            "loss:0.208854 [25632/60000]\n",
            "loss:0.174142 [28832/60000]\n",
            "loss:0.226367 [32032/60000]\n",
            "loss:0.175639 [35232/60000]\n",
            "loss:0.248670 [38432/60000]\n",
            "loss:0.167655 [41632/60000]\n",
            "loss:0.232433 [44832/60000]\n",
            "loss:0.220307 [48032/60000]\n",
            "loss:0.202375 [51232/60000]\n",
            "loss:0.171229 [54432/60000]\n",
            "loss:0.206067 [57632/60000]\n",
            "train_loss = 0.206445343708992, test_loss = 0.2065606899440479\n",
            "# Epoch 6\n",
            "loss:0.218173 [   32/60000]\n",
            "loss:0.174141 [ 3232/60000]\n",
            "loss:0.200156 [ 6432/60000]\n",
            "loss:0.186443 [ 9632/60000]\n",
            "loss:0.283670 [12832/60000]\n",
            "loss:0.216958 [16032/60000]\n",
            "loss:0.176631 [19232/60000]\n",
            "loss:0.204876 [22432/60000]\n",
            "loss:0.218240 [25632/60000]\n",
            "loss:0.193124 [28832/60000]\n",
            "loss:0.190506 [32032/60000]\n",
            "loss:0.222681 [35232/60000]\n",
            "loss:0.195899 [38432/60000]\n",
            "loss:0.195612 [41632/60000]\n",
            "loss:0.228641 [44832/60000]\n",
            "loss:0.211286 [48032/60000]\n",
            "loss:0.205029 [51232/60000]\n",
            "loss:0.197427 [54432/60000]\n",
            "loss:0.193532 [57632/60000]\n",
            "train_loss = 0.20644534327983857, test_loss = 0.20654790122478534\n",
            "# Epoch 7\n",
            "loss:0.205978 [   32/60000]\n",
            "loss:0.204870 [ 3232/60000]\n",
            "loss:0.164410 [ 6432/60000]\n",
            "loss:0.186717 [ 9632/60000]\n",
            "loss:0.168347 [12832/60000]\n",
            "loss:0.241902 [16032/60000]\n",
            "loss:0.197093 [19232/60000]\n",
            "loss:0.200651 [22432/60000]\n",
            "loss:0.192058 [25632/60000]\n",
            "loss:0.233130 [28832/60000]\n",
            "loss:0.213391 [32032/60000]\n",
            "loss:0.197696 [35232/60000]\n",
            "loss:0.180931 [38432/60000]\n",
            "loss:0.180872 [41632/60000]\n",
            "loss:0.194416 [44832/60000]\n",
            "loss:0.179579 [48032/60000]\n",
            "loss:0.230527 [51232/60000]\n",
            "loss:0.201066 [54432/60000]\n",
            "loss:0.208398 [57632/60000]\n",
            "train_loss = 0.20644534345467885, test_loss = 0.20648499247365104\n",
            "# Epoch 8\n",
            "loss:0.223764 [   32/60000]\n",
            "loss:0.217104 [ 3232/60000]\n",
            "loss:0.179264 [ 6432/60000]\n",
            "loss:0.218092 [ 9632/60000]\n",
            "loss:0.204402 [12832/60000]\n",
            "loss:0.196192 [16032/60000]\n",
            "loss:0.206665 [19232/60000]\n",
            "loss:0.204634 [22432/60000]\n",
            "loss:0.190678 [25632/60000]\n",
            "loss:0.195584 [28832/60000]\n",
            "loss:0.228882 [32032/60000]\n",
            "loss:0.225932 [35232/60000]\n",
            "loss:0.198936 [38432/60000]\n",
            "loss:0.238423 [41632/60000]\n",
            "loss:0.196371 [44832/60000]\n",
            "loss:0.199880 [48032/60000]\n",
            "loss:0.216798 [51232/60000]\n",
            "loss:0.182147 [54432/60000]\n",
            "loss:0.229755 [57632/60000]\n",
            "train_loss = 0.2064453434944153, test_loss = 0.206532693756655\n",
            "# Epoch 9\n",
            "loss:0.239312 [   32/60000]\n",
            "loss:0.202250 [ 3232/60000]\n",
            "loss:0.205732 [ 6432/60000]\n",
            "loss:0.187372 [ 9632/60000]\n",
            "loss:0.190073 [12832/60000]\n",
            "loss:0.217178 [16032/60000]\n",
            "loss:0.200806 [19232/60000]\n",
            "loss:0.182140 [22432/60000]\n",
            "loss:0.196597 [25632/60000]\n",
            "loss:0.214504 [28832/60000]\n",
            "loss:0.234268 [32032/60000]\n",
            "loss:0.209324 [35232/60000]\n",
            "loss:0.182967 [38432/60000]\n",
            "loss:0.173630 [41632/60000]\n",
            "loss:0.253796 [44832/60000]\n",
            "loss:0.214017 [48032/60000]\n",
            "loss:0.201643 [51232/60000]\n",
            "loss:0.209341 [54432/60000]\n",
            "loss:0.220714 [57632/60000]\n",
            "train_loss = 0.20644534347057342, test_loss = 0.2065281519969812\n",
            "# Epoch 10\n",
            "loss:0.225676 [   32/60000]\n",
            "loss:0.144550 [ 3232/60000]\n",
            "loss:0.196577 [ 6432/60000]\n",
            "loss:0.176672 [ 9632/60000]\n",
            "loss:0.259851 [12832/60000]\n",
            "loss:0.180189 [16032/60000]\n",
            "loss:0.183281 [19232/60000]\n",
            "loss:0.245968 [22432/60000]\n",
            "loss:0.182279 [25632/60000]\n",
            "loss:0.209422 [28832/60000]\n",
            "loss:0.195373 [32032/60000]\n",
            "loss:0.174804 [35232/60000]\n",
            "loss:0.221816 [38432/60000]\n",
            "loss:0.207323 [41632/60000]\n",
            "loss:0.207214 [44832/60000]\n",
            "loss:0.228384 [48032/60000]\n",
            "loss:0.189823 [51232/60000]\n",
            "loss:0.201926 [54432/60000]\n",
            "loss:0.198588 [57632/60000]\n",
            "train_loss = 0.206445343430837, test_loss = 0.20640613371952654\n",
            "# Epoch 11\n",
            "loss:0.182874 [   32/60000]\n",
            "loss:0.216529 [ 3232/60000]\n",
            "loss:0.203969 [ 6432/60000]\n",
            "loss:0.188611 [ 9632/60000]\n",
            "loss:0.188507 [12832/60000]\n",
            "loss:0.210713 [16032/60000]\n",
            "loss:0.181002 [19232/60000]\n",
            "loss:0.210056 [22432/60000]\n",
            "loss:0.181069 [25632/60000]\n",
            "loss:0.192353 [28832/60000]\n",
            "loss:0.183675 [32032/60000]\n",
            "loss:0.233237 [35232/60000]\n",
            "loss:0.220932 [38432/60000]\n",
            "loss:0.220683 [41632/60000]\n",
            "loss:0.195525 [44832/60000]\n",
            "loss:0.223928 [48032/60000]\n",
            "loss:0.187670 [51232/60000]\n",
            "loss:0.192318 [54432/60000]\n",
            "loss:0.233319 [57632/60000]\n",
            "train_loss = 0.20644534324804942, test_loss = 0.2065519022579772\n",
            "# Epoch 12\n",
            "loss:0.192374 [   32/60000]\n",
            "loss:0.217613 [ 3232/60000]\n",
            "loss:0.226971 [ 6432/60000]\n",
            "loss:0.224418 [ 9632/60000]\n",
            "loss:0.212817 [12832/60000]\n",
            "loss:0.187567 [16032/60000]\n",
            "loss:0.225624 [19232/60000]\n",
            "loss:0.208011 [22432/60000]\n",
            "loss:0.213686 [25632/60000]\n",
            "loss:0.230661 [28832/60000]\n",
            "loss:0.176209 [32032/60000]\n",
            "loss:0.240559 [35232/60000]\n",
            "loss:0.196446 [38432/60000]\n",
            "loss:0.200828 [41632/60000]\n",
            "loss:0.191688 [44832/60000]\n",
            "loss:0.238110 [48032/60000]\n",
            "loss:0.204299 [51232/60000]\n",
            "loss:0.215112 [54432/60000]\n",
            "loss:0.219303 [57632/60000]\n",
            "train_loss = 0.20644534306526183, test_loss = 0.20647980991643838\n",
            "# Epoch 13\n",
            "loss:0.228560 [   32/60000]\n",
            "loss:0.218890 [ 3232/60000]\n",
            "loss:0.196885 [ 6432/60000]\n",
            "loss:0.236127 [ 9632/60000]\n",
            "loss:0.179514 [12832/60000]\n",
            "loss:0.228142 [16032/60000]\n",
            "loss:0.181174 [19232/60000]\n",
            "loss:0.198603 [22432/60000]\n",
            "loss:0.177756 [25632/60000]\n",
            "loss:0.206428 [28832/60000]\n",
            "loss:0.217820 [32032/60000]\n",
            "loss:0.177907 [35232/60000]\n",
            "loss:0.230790 [38432/60000]\n",
            "loss:0.213397 [41632/60000]\n",
            "loss:0.217346 [44832/60000]\n",
            "loss:0.243352 [48032/60000]\n",
            "loss:0.233665 [51232/60000]\n",
            "loss:0.201392 [54432/60000]\n",
            "loss:0.206421 [57632/60000]\n",
            "train_loss = 0.20644534381230673, test_loss = 0.20652155673351533\n",
            "# Epoch 14\n",
            "loss:0.194368 [   32/60000]\n",
            "loss:0.193997 [ 3232/60000]\n",
            "loss:0.160423 [ 6432/60000]\n",
            "loss:0.200076 [ 9632/60000]\n",
            "loss:0.260830 [12832/60000]\n",
            "loss:0.208846 [16032/60000]\n",
            "loss:0.187932 [19232/60000]\n",
            "loss:0.177392 [22432/60000]\n",
            "loss:0.190342 [25632/60000]\n",
            "loss:0.235994 [28832/60000]\n",
            "loss:0.198795 [32032/60000]\n",
            "loss:0.220433 [35232/60000]\n",
            "loss:0.238905 [38432/60000]\n",
            "loss:0.197807 [41632/60000]\n",
            "loss:0.212549 [44832/60000]\n",
            "loss:0.170664 [48032/60000]\n",
            "loss:0.216445 [51232/60000]\n",
            "loss:0.198381 [54432/60000]\n",
            "loss:0.192821 [57632/60000]\n",
            "train_loss = 0.20644534350236257, test_loss = 0.20648688554002073\n",
            "# Epoch 15\n",
            "loss:0.216607 [   32/60000]\n",
            "loss:0.196166 [ 3232/60000]\n",
            "loss:0.229577 [ 6432/60000]\n",
            "loss:0.201372 [ 9632/60000]\n",
            "loss:0.223701 [12832/60000]\n",
            "loss:0.213425 [16032/60000]\n",
            "loss:0.207568 [19232/60000]\n",
            "loss:0.231764 [22432/60000]\n",
            "loss:0.189414 [25632/60000]\n",
            "loss:0.193676 [28832/60000]\n",
            "loss:0.203947 [32032/60000]\n",
            "loss:0.210223 [35232/60000]\n",
            "loss:0.220424 [38432/60000]\n",
            "loss:0.214318 [41632/60000]\n",
            "loss:0.208913 [44832/60000]\n",
            "loss:0.221255 [48032/60000]\n",
            "loss:0.217831 [51232/60000]\n",
            "loss:0.214956 [54432/60000]\n",
            "loss:0.219484 [57632/60000]\n",
            "train_loss = 0.20644534340699514, test_loss = 0.2064757703211361\n",
            "# Epoch 16\n",
            "loss:0.202206 [   32/60000]\n",
            "loss:0.177739 [ 3232/60000]\n",
            "loss:0.202924 [ 6432/60000]\n",
            "loss:0.187892 [ 9632/60000]\n",
            "loss:0.214769 [12832/60000]\n",
            "loss:0.197814 [16032/60000]\n",
            "loss:0.187855 [19232/60000]\n",
            "loss:0.197340 [22432/60000]\n",
            "loss:0.193583 [25632/60000]\n",
            "loss:0.232137 [28832/60000]\n",
            "loss:0.211293 [32032/60000]\n",
            "loss:0.212140 [35232/60000]\n",
            "loss:0.197838 [38432/60000]\n",
            "loss:0.214914 [41632/60000]\n",
            "loss:0.215364 [44832/60000]\n",
            "loss:0.219931 [48032/60000]\n",
            "loss:0.179264 [51232/60000]\n",
            "loss:0.240674 [54432/60000]\n",
            "loss:0.175208 [57632/60000]\n",
            "train_loss = 0.20644534353415173, test_loss = 0.20654174666435193\n",
            "# Epoch 17\n",
            "loss:0.192045 [   32/60000]\n",
            "loss:0.215293 [ 3232/60000]\n",
            "loss:0.210056 [ 6432/60000]\n",
            "loss:0.165857 [ 9632/60000]\n",
            "loss:0.196172 [12832/60000]\n",
            "loss:0.196420 [16032/60000]\n",
            "loss:0.176420 [19232/60000]\n",
            "loss:0.161367 [22432/60000]\n",
            "loss:0.211502 [25632/60000]\n",
            "loss:0.218267 [28832/60000]\n",
            "loss:0.190879 [32032/60000]\n",
            "loss:0.213455 [35232/60000]\n",
            "loss:0.212706 [38432/60000]\n",
            "loss:0.199849 [41632/60000]\n",
            "loss:0.195898 [44832/60000]\n",
            "loss:0.226282 [48032/60000]\n",
            "loss:0.232904 [51232/60000]\n",
            "loss:0.193703 [54432/60000]\n",
            "loss:0.215506 [57632/60000]\n",
            "train_loss = 0.20644534355799357, test_loss = 0.206517248346021\n",
            "# Epoch 18\n",
            "loss:0.200977 [   32/60000]\n",
            "loss:0.216413 [ 3232/60000]\n",
            "loss:0.193332 [ 6432/60000]\n",
            "loss:0.209258 [ 9632/60000]\n",
            "loss:0.238242 [12832/60000]\n",
            "loss:0.232390 [16032/60000]\n",
            "loss:0.224724 [19232/60000]\n",
            "loss:0.210275 [22432/60000]\n",
            "loss:0.202673 [25632/60000]\n",
            "loss:0.176206 [28832/60000]\n",
            "loss:0.215835 [32032/60000]\n",
            "loss:0.195920 [35232/60000]\n",
            "loss:0.224150 [38432/60000]\n",
            "loss:0.218835 [41632/60000]\n",
            "loss:0.199277 [44832/60000]\n",
            "loss:0.139648 [48032/60000]\n",
            "loss:0.201993 [51232/60000]\n",
            "loss:0.228500 [54432/60000]\n",
            "loss:0.186088 [57632/60000]\n",
            "train_loss = 0.20644534339110057, test_loss = 0.20648484284314103\n",
            "# Epoch 19\n",
            "loss:0.211201 [   32/60000]\n",
            "loss:0.255039 [ 3232/60000]\n",
            "loss:0.175218 [ 6432/60000]\n",
            "loss:0.216340 [ 9632/60000]\n",
            "loss:0.178845 [12832/60000]\n",
            "loss:0.191281 [16032/60000]\n",
            "loss:0.225464 [19232/60000]\n",
            "loss:0.195671 [22432/60000]\n",
            "loss:0.204051 [25632/60000]\n",
            "loss:0.247148 [28832/60000]\n",
            "loss:0.187597 [32032/60000]\n",
            "loss:0.247526 [35232/60000]\n",
            "loss:0.222608 [38432/60000]\n",
            "loss:0.207992 [41632/60000]\n",
            "loss:0.210123 [44832/60000]\n",
            "loss:0.230621 [48032/60000]\n",
            "loss:0.166554 [51232/60000]\n",
            "loss:0.190543 [54432/60000]\n",
            "loss:0.213102 [57632/60000]\n",
            "train_loss = 0.20644534362951913, test_loss = 0.2065520432715218\n"
          ]
        }
      ]
    }
  ]
}